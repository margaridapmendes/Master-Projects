{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTEzoMx6CasV"
      },
      "source": [
        "#### Copyright 2018 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IhmPj1VVCfWb"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ovTGnGws2vzf"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHK6DyunSbs4"
      },
      "source": [
        "# Cat vs. Dog Image Classification\n",
        "## Exercise 3: Feature Extraction and Fine-Tuning\n",
        "**_Estimated completion time: 30 minutes_**\n",
        "\n",
        "In Exercise 1, we built a convnet from scratch, and were able to achieve an accuracy of about 70%. With the addition of data augmentation and dropout in Exercise 2, we were able to increase accuracy to about 80%. That seems decent, but 20% is still too high of an error rate. Maybe we just don't have enough training data available to properly solve the problem. What other approaches can we try?\n",
        "\n",
        "In this exercise, we'll look at two techniques for repurposing feature data generated from image models that have already been trained on large sets of data, **feature extraction** and **fine tuning**, and use them to improve the accuracy of our cat vs. dog classification model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI5rmt4UBwXs"
      },
      "source": [
        "## Feature Extraction Using a Pretrained Model\n",
        "\n",
        "One thing that is commonly done in computer vision is to take a model trained on a very large dataset, run it on your own, smaller dataset, and extract the intermediate representations (features) that the model generates. These representations are frequently informative for your own computer vision task, even though the task may be quite different from the problem that the original model was trained on. This versatility and repurposability of convnets is one of the most interesting aspects of deep learning.\n",
        "\n",
        "In our case, we will use the [Inception V3 model](https://arxiv.org/abs/1512.00567) developed at Google, and pre-trained on [ImageNet](http://image-net.org/), a large dataset of web images (1.4M images and 1000 classes). This is a powerful model; let's see what the features that it has learned can do for our cat vs. dog problem.\n",
        "\n",
        "First, we need to pick which intermediate layer of Inception V3 we will use for feature extraction. A common practice is to use the output of the very last layer before the `Flatten` operation, the so-called \"bottleneck layer.\" The reasoning here is that the following fully connected layers will be too specialized for the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.\n",
        "\n",
        "Let's instantiate an Inception V3 model preloaded with weights trained on ImageNet:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1xJZ5glPPCRz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaXLMtYiF0t9"
      },
      "source": [
        "Now let's download the weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMrbllgAFipZ",
        "outputId": "15a273b8-46dc-4976-86c7-feda733d6e2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-12-18 01:12:59--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 108.177.121.128, 108.177.120.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   172MB/s    in 0.5s    \n",
            "\n",
            "2021-12-18 01:13:00 (172 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UnRiGBfOF8rq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = InceptionV3(\n",
        "    input_shape=(150, 150, 3), include_top=False, weights=None)\n",
        "pre_trained_model.load_weights(local_weights_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcYZPBS3bTAj"
      },
      "source": [
        "By specifying the `include_top=False` argument, we load a network that doesn't include the classification layers at the top—ideal for feature extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFxrqTuJee5m"
      },
      "source": [
        "Let's make the model non-trainable, since we will only use it for feature extraction; we won't update the weights of the pretrained model during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a38rB3lyedcB"
      },
      "outputs": [],
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGBGDiOAepnO"
      },
      "source": [
        "The layer we will use for feature extraction in Inception v3 is called `mixed7`. It is not the bottleneck of the network, but we are using it to keep a sufficiently large feature map (7x7 in this case). (Using the bottleneck layer would have resulting in a 3x3 feature map, which is a bit small.) Let's get the output from `mixed7`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj4rXshqbQlS",
        "outputId": "7802a8e0-21dc-4dc2-e6a1-b4755a3ea00f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "last layer output shape: (None, 7, 7, 768)\n"
          ]
        }
      ],
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxHk6XQLeUWh"
      },
      "source": [
        "Now let's stick a fully connected classifier on top of `last_output`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMXb913pbvFg",
        "outputId": "8b22080e-83ff-4099-dc79-2c9de7094230"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Configure and compile the model\n",
        "model = Model(pre_trained_model.input, x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.0001),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ECjowwV5Ug"
      },
      "source": [
        "For examples and data preprocessing, let's use the same files and `train_generator` as we did in Exercise 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl-IqOTjZVw_"
      },
      "source": [
        "**NOTE:** The 2,000 images used in this exercise are excerpted from the [\"Dogs vs. Cats\" dataset](https://www.kaggle.com/c/dogs-vs-cats/data) available on Kaggle, which contains 25,000 images. Here, we use a subset of the full dataset to decrease training time for educational purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4s8HckqGlnb",
        "outputId": "ead987c7-52e1-49c1-ca18-3b2cf51891ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-12-18 01:13:03--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.198.128, 64.233.191.128, 173.194.192.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.198.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   134MB/s    in 0.5s    \n",
            "\n",
            "2021-12-18 01:13:03 (134 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "   https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip -O \\\n",
        "   /tmp/cats_and_dogs_filtered.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl9XXARuV_eg",
        "outputId": "08bc1f33-f6a6-4539-c537-4581dc0fb3d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEC1AL7iVRLz"
      },
      "source": [
        "Finally, let's train the model using the features we extracted. We'll train on all 2000 images available, for 2 epochs, and validate on all 1,000 validation images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Blhq2MAUeyGA",
        "outputId": "68b6987a-4b16-4752-de98-98245b80b5eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 - 170s - loss: 0.3575 - acc: 0.8665 - val_loss: 0.1294 - val_acc: 0.9460 - 170s/epoch - 2s/step\n",
            "Epoch 2/10\n",
            "100/100 - 160s - loss: 0.2313 - acc: 0.9125 - val_loss: 0.0950 - val_acc: 0.9620 - 160s/epoch - 2s/step\n",
            "Epoch 3/10\n",
            "100/100 - 160s - loss: 0.2058 - acc: 0.9165 - val_loss: 0.1768 - val_acc: 0.9390 - 160s/epoch - 2s/step\n",
            "Epoch 4/10\n",
            "100/100 - 164s - loss: 0.2005 - acc: 0.9285 - val_loss: 0.1299 - val_acc: 0.9600 - 164s/epoch - 2s/step\n",
            "Epoch 5/10\n",
            "100/100 - 162s - loss: 0.1922 - acc: 0.9315 - val_loss: 0.0951 - val_acc: 0.9650 - 162s/epoch - 2s/step\n",
            "Epoch 6/10\n",
            "100/100 - 160s - loss: 0.1642 - acc: 0.9390 - val_loss: 0.1288 - val_acc: 0.9550 - 160s/epoch - 2s/step\n",
            "Epoch 7/10\n",
            "100/100 - 159s - loss: 0.1582 - acc: 0.9415 - val_loss: 0.1510 - val_acc: 0.9580 - 159s/epoch - 2s/step\n",
            "Epoch 8/10\n",
            "100/100 - 161s - loss: 0.1844 - acc: 0.9375 - val_loss: 0.0923 - val_acc: 0.9710 - 161s/epoch - 2s/step\n",
            "Epoch 9/10\n",
            "100/100 - 157s - loss: 0.1643 - acc: 0.9405 - val_loss: 0.1224 - val_acc: 0.9630 - 157s/epoch - 2s/step\n",
            "Epoch 10/10\n",
            "100/100 - 164s - loss: 0.1794 - acc: 0.9400 - val_loss: 0.1351 - val_acc: 0.9650 - 164s/epoch - 2s/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=10,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S8hwTr0e55BQ",
        "outputId": "2ffbe7ba-5aa1-45d0-923a-e223a94e78dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 37632)        0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1024)         38536192    ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            1025        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRjyAkE62aOG"
      },
      "source": [
        "You can see that we reach a validation accuracy of 88–90% very quickly. This is much better than the small model we trained from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt15y6IS2pBo"
      },
      "source": [
        "## Further Improving Accuracy with Fine-Tuning\n",
        "\n",
        "In our feature-extraction experiment, we only tried adding two classification layers on top of an Inception V3 layer. The weights of the pretrained network were not updated during training. One way to increase performance even further is to \"fine-tune\" the weights of the top layers of the pretrained model alongside the training of the top-level classifier. A couple of important notes on fine-tuning:\n",
        "\n",
        "- **Fine-tuning should only be attempted *after* you have trained the top-level classifier with the pretrained model set to non-trainable**. If you add a randomly initialized classifier on top of a pretrained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier), and your pretrained model will just forget everything it has learned.\n",
        "- Additionally, we **fine-tune only the *top layers* of the pre-trained model** rather than all layers of the pretrained model because, in a convnet, the higher up a layer is, the more specialized it is. The first few layers in a convnet learn very simple and generic features, which generalize to almost all types of images. But as you go higher up, the features are increasingly specific to the dataset that the model is trained on. The goal of fine-tuning is to adapt these specialized features to work with the new dataset.\n",
        "\n",
        "All we need to do to implement fine-tuning is to set the top layers of Inception V3 to be trainable, recompile the model (necessary for these changes to take effect), and resume training. Let's unfreeze all layers belonging to the `mixed7` module—i.e., all layers found after `mixed6`—and recompile the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_l_J4S0Z2rgg",
        "outputId": "eaf05e53-0e7b-4f00-b9f7-68cab13c9746"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "unfreeze = False\n",
        "\n",
        "# Unfreeze all models after \"mixed6\"\n",
        "for layer in pre_trained_model.layers:\n",
        "  if unfreeze:\n",
        "    layer.trainable = True\n",
        "  if layer.name == 'mixed6':\n",
        "    unfreeze = True\n",
        "\n",
        "# As an optimizer, here we will use SGD \n",
        "# with a very low learning rate (0.00001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=SGD(\n",
        "                  lr=0.00001, \n",
        "                  momentum=0.9),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE37ARlqY9da"
      },
      "source": [
        "Now let's retrain the model. We'll train on all 2000 images available, for 50 epochs, and validate on all 1,000 validation images. (This may take 15-20 minutes to run.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_GgDGG4Y_hJ",
        "outputId": "5aae0e0f-b08f-4717-b7e7-711f53f377d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "100/100 - 28s - loss: 0.3048 - acc: 0.8745 - val_loss: 0.1563 - val_acc: 0.9400 - 28s/epoch - 281ms/step\n",
            "Epoch 2/50\n",
            "100/100 - 22s - loss: 0.2424 - acc: 0.8930 - val_loss: 0.1434 - val_acc: 0.9430 - 22s/epoch - 224ms/step\n",
            "Epoch 3/50\n",
            "100/100 - 22s - loss: 0.1968 - acc: 0.9175 - val_loss: 0.1375 - val_acc: 0.9460 - 22s/epoch - 220ms/step\n",
            "Epoch 4/50\n",
            "100/100 - 22s - loss: 0.1942 - acc: 0.9250 - val_loss: 0.1316 - val_acc: 0.9460 - 22s/epoch - 221ms/step\n",
            "Epoch 5/50\n",
            "100/100 - 22s - loss: 0.1756 - acc: 0.9255 - val_loss: 0.1291 - val_acc: 0.9470 - 22s/epoch - 218ms/step\n",
            "Epoch 6/50\n",
            "100/100 - 22s - loss: 0.1697 - acc: 0.9290 - val_loss: 0.1249 - val_acc: 0.9500 - 22s/epoch - 220ms/step\n",
            "Epoch 7/50\n",
            "100/100 - 23s - loss: 0.1691 - acc: 0.9320 - val_loss: 0.1237 - val_acc: 0.9540 - 23s/epoch - 228ms/step\n",
            "Epoch 8/50\n",
            "100/100 - 22s - loss: 0.1692 - acc: 0.9290 - val_loss: 0.1230 - val_acc: 0.9560 - 22s/epoch - 219ms/step\n",
            "Epoch 9/50\n",
            "100/100 - 23s - loss: 0.1792 - acc: 0.9230 - val_loss: 0.1215 - val_acc: 0.9580 - 23s/epoch - 227ms/step\n",
            "Epoch 10/50\n",
            "100/100 - 22s - loss: 0.1871 - acc: 0.9245 - val_loss: 0.1205 - val_acc: 0.9580 - 22s/epoch - 219ms/step\n",
            "Epoch 11/50\n",
            "100/100 - 22s - loss: 0.1727 - acc: 0.9315 - val_loss: 0.1193 - val_acc: 0.9590 - 22s/epoch - 221ms/step\n",
            "Epoch 12/50\n",
            "100/100 - 21s - loss: 0.1847 - acc: 0.9275 - val_loss: 0.1180 - val_acc: 0.9600 - 21s/epoch - 213ms/step\n",
            "Epoch 13/50\n",
            "100/100 - 22s - loss: 0.1814 - acc: 0.9210 - val_loss: 0.1171 - val_acc: 0.9620 - 22s/epoch - 215ms/step\n",
            "Epoch 14/50\n",
            "100/100 - 22s - loss: 0.1696 - acc: 0.9380 - val_loss: 0.1171 - val_acc: 0.9610 - 22s/epoch - 217ms/step\n",
            "Epoch 15/50\n",
            "100/100 - 22s - loss: 0.1715 - acc: 0.9320 - val_loss: 0.1165 - val_acc: 0.9610 - 22s/epoch - 220ms/step\n",
            "Epoch 16/50\n",
            "100/100 - 23s - loss: 0.1611 - acc: 0.9355 - val_loss: 0.1158 - val_acc: 0.9620 - 23s/epoch - 228ms/step\n",
            "Epoch 17/50\n",
            "100/100 - 22s - loss: 0.1723 - acc: 0.9360 - val_loss: 0.1156 - val_acc: 0.9620 - 22s/epoch - 221ms/step\n",
            "Epoch 18/50\n",
            "100/100 - 23s - loss: 0.1759 - acc: 0.9265 - val_loss: 0.1147 - val_acc: 0.9620 - 23s/epoch - 228ms/step\n",
            "Epoch 19/50\n",
            "100/100 - 22s - loss: 0.1589 - acc: 0.9360 - val_loss: 0.1135 - val_acc: 0.9620 - 22s/epoch - 219ms/step\n",
            "Epoch 20/50\n",
            "100/100 - 22s - loss: 0.1630 - acc: 0.9380 - val_loss: 0.1141 - val_acc: 0.9610 - 22s/epoch - 224ms/step\n",
            "Epoch 21/50\n",
            "100/100 - 22s - loss: 0.1589 - acc: 0.9340 - val_loss: 0.1134 - val_acc: 0.9620 - 22s/epoch - 218ms/step\n",
            "Epoch 22/50\n",
            "100/100 - 23s - loss: 0.1679 - acc: 0.9330 - val_loss: 0.1126 - val_acc: 0.9620 - 23s/epoch - 227ms/step\n",
            "Epoch 23/50\n",
            "100/100 - 22s - loss: 0.1677 - acc: 0.9300 - val_loss: 0.1125 - val_acc: 0.9620 - 22s/epoch - 218ms/step\n",
            "Epoch 24/50\n",
            "100/100 - 22s - loss: 0.1707 - acc: 0.9305 - val_loss: 0.1116 - val_acc: 0.9620 - 22s/epoch - 224ms/step\n",
            "Epoch 25/50\n",
            "100/100 - 22s - loss: 0.1630 - acc: 0.9360 - val_loss: 0.1115 - val_acc: 0.9620 - 22s/epoch - 220ms/step\n",
            "Epoch 26/50\n",
            "100/100 - 22s - loss: 0.1653 - acc: 0.9315 - val_loss: 0.1111 - val_acc: 0.9620 - 22s/epoch - 223ms/step\n",
            "Epoch 27/50\n",
            "100/100 - 22s - loss: 0.1649 - acc: 0.9340 - val_loss: 0.1103 - val_acc: 0.9620 - 22s/epoch - 217ms/step\n",
            "Epoch 28/50\n",
            "100/100 - 22s - loss: 0.1605 - acc: 0.9335 - val_loss: 0.1094 - val_acc: 0.9620 - 22s/epoch - 217ms/step\n",
            "Epoch 29/50\n",
            "100/100 - 23s - loss: 0.1652 - acc: 0.9340 - val_loss: 0.1089 - val_acc: 0.9620 - 23s/epoch - 227ms/step\n",
            "Epoch 30/50\n",
            "100/100 - 22s - loss: 0.1530 - acc: 0.9360 - val_loss: 0.1087 - val_acc: 0.9620 - 22s/epoch - 219ms/step\n",
            "Epoch 31/50\n",
            "100/100 - 23s - loss: 0.1506 - acc: 0.9440 - val_loss: 0.1086 - val_acc: 0.9620 - 23s/epoch - 227ms/step\n",
            "Epoch 32/50\n",
            "100/100 - 22s - loss: 0.1636 - acc: 0.9290 - val_loss: 0.1085 - val_acc: 0.9620 - 22s/epoch - 220ms/step\n",
            "Epoch 33/50\n",
            "100/100 - 23s - loss: 0.1665 - acc: 0.9280 - val_loss: 0.1082 - val_acc: 0.9620 - 23s/epoch - 226ms/step\n",
            "Epoch 34/50\n",
            "100/100 - 22s - loss: 0.1619 - acc: 0.9370 - val_loss: 0.1074 - val_acc: 0.9620 - 22s/epoch - 218ms/step\n",
            "Epoch 35/50\n",
            "100/100 - 22s - loss: 0.1557 - acc: 0.9375 - val_loss: 0.1065 - val_acc: 0.9620 - 22s/epoch - 223ms/step\n",
            "Epoch 36/50\n",
            "100/100 - 22s - loss: 0.1450 - acc: 0.9410 - val_loss: 0.1066 - val_acc: 0.9630 - 22s/epoch - 218ms/step\n",
            "Epoch 37/50\n",
            "100/100 - 22s - loss: 0.1421 - acc: 0.9445 - val_loss: 0.1059 - val_acc: 0.9630 - 22s/epoch - 218ms/step\n",
            "Epoch 38/50\n",
            "100/100 - 23s - loss: 0.1717 - acc: 0.9345 - val_loss: 0.1057 - val_acc: 0.9620 - 23s/epoch - 227ms/step\n",
            "Epoch 39/50\n",
            "100/100 - 22s - loss: 0.1575 - acc: 0.9400 - val_loss: 0.1048 - val_acc: 0.9630 - 22s/epoch - 218ms/step\n",
            "Epoch 40/50\n",
            "100/100 - 22s - loss: 0.1615 - acc: 0.9325 - val_loss: 0.1044 - val_acc: 0.9630 - 22s/epoch - 224ms/step\n",
            "Epoch 41/50\n",
            "100/100 - 22s - loss: 0.1612 - acc: 0.9330 - val_loss: 0.1044 - val_acc: 0.9630 - 22s/epoch - 219ms/step\n",
            "Epoch 42/50\n",
            "100/100 - 22s - loss: 0.1582 - acc: 0.9360 - val_loss: 0.1044 - val_acc: 0.9620 - 22s/epoch - 222ms/step\n",
            "Epoch 43/50\n",
            "100/100 - 22s - loss: 0.1510 - acc: 0.9415 - val_loss: 0.1045 - val_acc: 0.9630 - 22s/epoch - 217ms/step\n",
            "Epoch 44/50\n",
            "100/100 - 22s - loss: 0.1450 - acc: 0.9415 - val_loss: 0.1042 - val_acc: 0.9620 - 22s/epoch - 219ms/step\n",
            "Epoch 45/50\n",
            "100/100 - 22s - loss: 0.1418 - acc: 0.9425 - val_loss: 0.1046 - val_acc: 0.9630 - 22s/epoch - 218ms/step\n",
            "Epoch 46/50\n",
            "100/100 - 22s - loss: 0.1556 - acc: 0.9400 - val_loss: 0.1044 - val_acc: 0.9620 - 22s/epoch - 221ms/step\n",
            "Epoch 47/50\n",
            "100/100 - 22s - loss: 0.1498 - acc: 0.9375 - val_loss: 0.1036 - val_acc: 0.9620 - 22s/epoch - 223ms/step\n",
            "Epoch 48/50\n",
            "100/100 - 23s - loss: 0.1601 - acc: 0.9355 - val_loss: 0.1026 - val_acc: 0.9620 - 23s/epoch - 226ms/step\n",
            "Epoch 49/50\n",
            "100/100 - 23s - loss: 0.1414 - acc: 0.9425 - val_loss: 0.1024 - val_acc: 0.9630 - 23s/epoch - 230ms/step\n",
            "Epoch 50/50\n",
            "100/100 - 22s - loss: 0.1521 - acc: 0.9410 - val_loss: 0.1015 - val_acc: 0.9640 - 22s/epoch - 219ms/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=50,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EPGn58ofwq5"
      },
      "source": [
        "We are seeing a nice improvement, with the validation loss going from ~1.7 down to ~1.2, and accuracy going from 88% to 92%. That's a 4.5% relative improvement in accuracy.\n",
        "\n",
        "Let's plot the training and validation loss and accuracy to show it conclusively:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1FtxcKjJfxL9",
        "outputId": "2fb6ce3e-14f8-4092-e657-2de045d8c4a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9fnA8c+Tm71DCCGMJCBLkCUBRHFRraggaq2iOEul1tpfW62rtmptba221rbuqrhqlVK1qCAOQEVACHvICGEkgZAwAoGQ/fz+OCdwCRk3G3Kf9+t1ufd+z7jfk4Tz3O8WVcUYY4z/CWjrDBhjjGkbFgCMMcZPWQAwxhg/ZQHAGGP8lAUAY4zxUxYAjDHGT1kAMM1GRGaJyE3NvW9bEpGtInJBC5xXRaSX+/p5EfmNL/s24nMmicgnjc1nHec9T0Sym/u8pnUFtnUGTNsSkYNeb8OBEqDCff8jVf2Xr+dS1YtbYt/2TlVva47ziEgqsAUIUtVy99z/Anz+HRr/YgHAz6lqZNVrEdkK/FBVP6u+n4gEVt1UjDHtg1UBmRpVFfFF5F4RyQWmikiciHwoIvkiss993c3rmHki8kP39c0iMl9E/uzuu0VELm7kvj1E5EsRKRSRz0TkGRF5s5Z8+5LH34nI1+75PhGRjl7bbxCRbSKyR0QeqOPnM1JEckXE45V2hYiscl+PEJGFIlIgIjtF5GkRCa7lXK+KyO+93t/tHrNDRH5Qbd9LRWS5iBwQkSwRedhr85fuc4GIHBSRUVU/W6/jzxSRJSKy330+09efTV1E5FT3+AIRWSsil3ltu0RE1rnnzBGRX7rpHd3fT4GI7BWRr0TE7kmtyH7Ypi6dgQ5ACjAF5+9lqvs+GTgMPF3H8SOBDUBH4HHgZRGRRuz7FrAYiAceBm6o4zN9yeN1wC1AJyAYqLoh9Qeec8/fxf28btRAVb8BDgFjqp33Lfd1BfAL93pGAd8Bbq8j37h5GOvm50KgN1C9/eEQcCMQC1wK/FhELne3neM+x6pqpKourHbuDsBHwN/da3sS+EhE4qtdw3E/m3ryHAR8AHziHvdT4F8i0tfd5WWc6sQo4DRgjpt+F5ANJACJwK8Am5umFVkAMHWpBB5S1RJVPayqe1T1v6papKqFwKPAuXUcv01V/6mqFcBrQBLOf3Sf9xWRZGA48KCqlqrqfGBGbR/oYx6nqupGVT0MTAOGuOlXAR+q6peqWgL8xv0Z1ObfwLUAIhIFXOKmoapLVXWRqpar6lbghRryUZOr3fytUdVDOAHP+/rmqepqVa1U1VXu5/lyXnACxiZVfcPN17+B9cB4r31q+9nU5QwgEnjM/R3NAT7E/dkAZUB/EYlW1X2quswrPQlIUdUyVf1KbXKyVmUBwNQlX1WLq96ISLiIvOBWkRzAqXKI9a4GqSa36oWqFrkvIxu4bxdgr1caQFZtGfYxj7ler4u88tTF+9zuDXhPbZ+F823/ShEJAa4ElqnqNjcffdzqjVw3H3/AKQ3U55g8ANuqXd9IEZnrVnHtB27z8bxV595WLW0b0NXrfW0/m3rzrKrewdL7vN/DCY7bROQLERnlpj8BZACfiEimiNzn22WY5mIBwNSl+rexu4C+wEhVjeZolUNt1TrNYSfQQUTCvdK617F/U/K40/vc7mfG17azqq7DudFdzLHVP+BUJa0Herv5+FVj8oBTjeXtLZwSUHdVjQGe9zpvfd+ed+BUjXlLBnJ8yFd95+1erf7+yHlVdYmqTsCpHnofp2SBqhaq6l2q2hO4DLhTRL7TxLyYBrAAYBoiCqdOvcCtT36opT/Q/UadDjwsIsHut8fxdRzSlDxOB8aJyGi3wfYR6v8/8hbwM5xA859q+TgAHBSRfsCPfczDNOBmEenvBqDq+Y/CKREVi8gInMBTJR+nyqpnLeeeCfQRketEJFBErgH641TXNMU3OKWFe0QkSETOw/kdve3+ziaJSIyqluH8TCoBRGSciPRy23r247Sb1FXlZpqZBQDTEE8BYcBuYBHwcSt97iSchtQ9wO+Bd3DGK9Sk0XlU1bXAT3Bu6juBfTiNlHWpqoOfo6q7vdJ/iXNzLgT+6ebZlzzMcq9hDk71yJxqu9wOPCIihcCDuN+m3WOLcNo8vnZ71pxR7dx7gHE4paQ9wD3AuGr5bjBVLcW54V+M83N/FrhRVde7u9wAbHWrwm7D+X2C08j9GXAQWAg8q6pzm5IX0zBibS7mZCMi7wDrVbXFSyDGtGdWAjAnPBEZLiKniEiA201yAk5dsjGmCWwksDkZdAbexWmQzQZ+rKrL2zZLxpz8rArIGGP8lFUBGWOMnzqpqoA6duyoqampbZ0NY4w5qSxdunS3qiZUTz+pAkBqairp6eltnQ1jjDmpiEj1EeCAVQEZY4zfsgBgjDF+ygKAMcb4KQsAxhjjpywAGGOMn7IAYIwxfsoCgDHG+Cm/CADvL8/hzUU1doM1xhi/5RcBYObqnbyx0AKAMcZ484sAkBgdyq7C4vp3NMYYP+JTABCRsSKyQUQyalq4WURuE5HVIrJCROaLSH+vbfe7x20QkYt8PWdzSowOoaCojOKyipb8GGOMOanUGwBExAM8g7PcW3/gWu8bvOstVR2oqkOAx4En3WP7AxOBAcBY4FkR8fh4zmbTKToUgPzC2lYRNMYY/+NLCWAEkKGqme7an2/jrMh0hKoe8HobAVQtMjABeFtVS1R1C84apyN8OWdzSnQDQO4BqwYyxpgqvswG2hXI8nqfDYysvpOI/AS4EwgGxngdu6jasV3d1/We0z3vFGAKQHJysg/ZPV5nNwDssgBgjDFHNFsjsKo+o6qnAPcCv27G876oqmmqmpaQcNx01j5JjA4BYNcBqwIyxpgqvpQAcoDuXu+7uWm1eRt4zodjG3LOJokJCyI4MIA8KwEYY8wRvpQAlgC9RaSHiATjNOrO8N5BRHp7vb0U2OS+ngFMFJEQEekB9AYW+3LO5iQiJEaHWBWQMcZ4qbcEoKrlInIHMBvwAK+o6loReQRIV9UZwB0icgFQBuwDbnKPXSsi04B1QDnwE1WtAKjpnM1/eUclRoVaFZAxxnjxaUlIVZ0JzKyW9qDX65/VceyjwKO+nLMlJcaE8u2OA/XvaIwxfsIvRgJDVQnAqoCMMaaK/wSA6BAOlVZwsKS8rbNijDEnBD8KADYWwBhjvPlNAOh0ZCyABQBjjAE/CgBWAjDGmGP5YQCwrqDGGAN+FAAiQwKJDAm0EoAxxrj8JgCA0w6QZyUAY4wB/CwA2FgAY4w5yr8CQHSIrQlgjDEu/woAMaHkHShBVevf2Rhj2jn/CgBRoZRWVFJQVNbWWTHGmDbnXwGgqitooVUDGWOMnwUAWxnMGGOq+FkAsNHAxhhTxacAICJjRWSDiGSIyH01bL9TRNaJyCoR+VxEUtz080VkhdejWEQud7e9KiJbvLYNad5LO96R+YD2WwAwxph6F4QREQ/wDHAhkA0sEZEZqrrOa7flQJqqFonIj4HHgWtUdS4wxD1PByAD+MTruLtVdXrzXEr9QgI9xIUHWRuAMcbgWwlgBJChqpmqWoqz6PsE7x1Uda6qFrlvF+Es8l7dVcAsr/3aRGK0LQ1pjDHgWwDoCmR5vc9202ozGZhVQ/pE4N/V0h51q43+KiIhNZ1MRKaISLqIpOfn5/uQ3bp1ig4lz9oAjDGmeRuBReR6IA14olp6EjAQZxH4KvcD/YDhQAfg3prOqaovqmqaqqYlJCQ0OY+JUSFWAjDGGHwLADlAd6/33dy0Y4jIBcADwGWqWv0OezXwnqoeGYGlqjvVUQJMxalqanGdY0LJP1hCRaWNBjbG+DdfAsASoLeI9BCRYJyqnBneO4jIUOAFnJt/Xg3nuJZq1T9uqQAREeByYE3Ds99wnaJDqahU9hy0UoAxxr/V2wtIVctF5A6c6hsP8IqqrhWRR4B0VZ2BU+UTCfzHuZ+zXVUvAxCRVJwSxBfVTv0vEUkABFgB3NYsV1SPxKijg8E6ueMCjDHGH9UbAABUdSYws1rag16vL6jj2K3U0GisqmN8zmUz8h4MNpCYtsiCMcacEPxqJDDYfEDGGFPF7wJAx8hgAsRGAxtjjN8FgEBPAB0jrSuoMcb4XQAAdzSwVQEZY/ycnwYAKwEYY4xfBgCbDsIYY/w0ACRGhbLnUCml5ZVtnRVjjGkzfhkAOsc4g8HyrB3AGOPH/DIAdDoyGMzaAYwx/ssvA0BilBMArB3AGOPP/DMAHFkc3gKAMcZ/+WUAiAsPJsgj7Cq0KiBjjP/yywAQECB0igq16SCMMX7NLwMAuIPBrBeQMcaP+XEAsMXhjTH+zacAICJjRWSDiGSIyH01bL9TRNa5C7x/LiIpXtsqRGSF+5jhld5DRL5xz/mOu9pYq3ECgJUAjDH+q94AICIe4BngYqA/cK2I9K+223IgTVUHAdOBx722HVbVIe7jMq/0PwF/VdVewD5gchOuo8E6RYdQWFxOUWl5a36sMcacMHwpAYwAMlQ1U1VLgbeBCd47qOpcVS1y3y7CWTi+Vu46wGNwggXAazjrAreao2MBrBrIGOOffAkAXYEsr/fZ1LDEo5fJwCyv96Eiki4ii0Sk6iYfDxSoatXX7/rO2ew6xzgBINeqgYwxfsqnNYF9JSLXA2nAuV7JKaqaIyI9gTkishrY34BzTgGmACQnJzdbXm0wmDHG3/lSAsgBunu97+amHUNELgAeAC5T1SP1Kqqa4z5nAvOAocAeIFZEqgJQjed0j3tRVdNUNS0hIcGH7Pqmaj4gqwIyxvgrXwLAEqC322snGJgIzPDeQUSGAi/g3PzzvNLjRCTEfd0ROAtYp6oKzAWucne9CfhfUy+mIaJCAgkL8lgJwBjjt+oNAG49/R3AbOBbYJqqrhWRR0SkqlfPE0Ak8J9q3T1PBdJFZCXODf8xVV3nbrsXuFNEMnDaBF5utqvygYi4g8GsBGCM8U8+tQGo6kxgZrW0B71eX1DLcQuAgbVsy8TpYdRmEqNtOghjjP/y25HAYIvDG2P8m58HgBBy9xfjNEkYY4x/8esA0DU2jJLySvYcKm3rrBhjTKvz6wCQEh8BwLY9h9o4J8YY0/r8PACEA7B1d1E9expjTPvj1wGgW1w4AWIlAGOMf/LrABAcGEDXuDC27rESgDHG//h1AABIjY+wEoAxxi/5fQBIiQ9n214rARhj/I/fB4DU+AgKisooKLKuoMYY/+L3ASC5g9MTaJu1Axhj/IzfB4DUjs5YgK3WDmCM8TN+HwCsBGCM8Vd+HwBCgzwkxYRaCcAY43f8PgCA2xPISgDGGD9jAQAbC2CM8U8+BQARGSsiG0QkQ0Tuq2H7nSKyTkRWicjnIpLipg8RkYUistbddo3XMa+KyBZ3BbEVIjKk+S6rYVLiI9h9sJSDJeVtlQVjjGl19QYAEfEAzwAXA/2Ba0Wkf7XdlgNpqjoImA487qYXATeq6gBgLPCUiMR6HXe3qg5xHyuaeC2NVjUpnJUCjDH+xJcSwAggQ1UzVbUUeBuY4L2Dqs5V1apK9EVANzd9o6pucl/vAPKAhObKfHM5GgCsHcAY4z98CQBdgSyv99luWm0mA7OqJ4rICCAY2OyV/KhbNfRXEQmp6WQiMkVE0kUkPT8/34fsNlzVugDWE8gY40+atRFYRK4H0oAnqqUnAW8At6hqpZt8P9APGA50AO6t6Zyq+qKqpqlqWkJCyxQeIkMC6RgZwjZbF8AY40d8CQA5QHev993ctGOIyAXAA8BlqlrilR4NfAQ8oKqLqtJVdac6SoCpOFVNbSY1PtxKAMYYv+JLAFgC9BaRHiISDEwEZnjvICJDgRdwbv55XunBwHvA66o6vdoxSe6zAJcDa5pyIU2VEh9hbQDGGL9SbwBQ1XLgDmA28C0wTVXXisgjInKZu9sTQCTwH7dLZ1WAuBo4B7i5hu6e/xKR1cBqoCPw++a7rIZLjQ8n90AxxWUVbZkNY4xpNYG+7KSqM4GZ1dIe9Hp9QS3HvQm8Wcu2Mb5ns+WluJPCbd9bRJ/EqDbOjTHGtDwbCexK6VC1QLy1Axhj/IMFAFeq2xXU2gGMMf7CAoArJjyI2PAg6wlkjPEbFgC8WE8gY4w/sQDgxcYCGGP8iQUALynxEewoOExJuXUFNca0fxYAvKTGh1OpkL3vcFtnxRhjWpwFAC9Vs4Jut3YAY4wfsADgxWYFNcb4EwsAXuIjgokMCbSeQMYYv2ABwIuIkGI9gYwxfsICQDWpNhbAGOMnLABUkxIfTtbeIsorKuvf2RhjTmIWAKpJjY+gvFLZUVDc1lkxxpgWZQGgmmS3K6i1Axhj2jufAoCIjBWRDSKSISL31bD9ThFZ5y7w/rmIpHhtu0lENrmPm7zSh4nIavecf3dXBmtzR2YF3WvtAMaY9q3eACAiHuAZ4GKgP3CtiPSvtttyIE1VBwHTgcfdYzsADwEjcdb8fUhE4txjngNuBXq7j7FNvppm0CkqhNCgALbZugDGmHbOlxLACCBDVTNVtRR4G5jgvYOqzlXVqq/Mi3AWjge4CPhUVfeq6j7gU2Csux5wtKouUlUFXsdZF7jNBQQIKR0i2Go9gYwx7ZwvAaArkOX1PttNq81kYFY9x3Z1X9d7ThGZIiLpIpKen5/vQ3abLiU+nG3WBmCMaeeatRFYRK4H0nAWiW8WqvqiqqapalpCQkJznbZOqR0j2La3iMpKbZXPM8aYtuBLAMgBunu97+amHUNELgAeAC5T1ZJ6js3haDVRredsKynx4ZSWV7Ju54G2zooxxrQYXwLAEqC3iPQQkWBgIjDDewcRGQq8gHPzz/PaNBv4rojEuY2/3wVmq+pO4ICInOH2/rkR+F8zXE+zGJ7agWBPAOOfns/NUxfzydpcGxhmjGl3AuvbQVXLReQOnJu5B3hFVdeKyCNAuqrOwKnyiQT+4/bm3K6ql6nqXhH5HU4QAXhEVfe6r28HXgXCcNoMZnGC6JMYxdy7z+Odxdt5Jz2LKW8spXN0KNcM787EEd1Jiglr6ywaY0yTidMJ5+SQlpam6enprfqZ5RWVfL4+j7e+2c6Xm/IR4KWb0hjTL7FV82GMMY0lIktVNa16uo0ErkegJ4CLBnTmtR+M4Mu7zycpJozXFmxr62wZY0yTWQBogO4dwhk/uAtfZ+xm76HSts6OMcY0iQWABho/OInySuXjNbltnRVjjGkSCwAN1D8pmp4JEXywckdbZ8UYY5rEAkADiQjjB3Vh0ZY95B2wKaONMScvCwCNMH5wEqrw0eqdbZ0VAFTVRi0bYxrMAkAj9OoUxalJ0Xy4qu0DwMGSci5/5mvunr6qrbNijDnJWABopHGDkli6bR/Z+9pu1tDKSuWuaStYmb2fd5dns9WmsDbGNIAFgEYaP6gLAB+1YSng6bkZzF67i9vOPYXAAOHVBVt9Om7djgNMeT2duRvyOJkGAhpjmpcFgEZKjg9ncPdYPljVNr2BPl23iyc/3ciVQ7ty79i+jB/chWnpWew/XFbncarKwzPW8sm6XdwydQnff34hCzfvaaVcG2NOJBYAmmD8oCTW5BwgM/9gq35uRl4hv3hnBYO6xfCHKwciIkwe3YOi0greXry9zmPnbcxn8da9PDS+P7+//DSy9hVx7T8XMemlRSzbvq+VrsAYcyKwANAE4wZ1QYRWbQzef7iMW19fSmhQAM9fP4zQIA8AA7rEMKpnPK8u2EpZLTOXVlYqj3+8gZT4cK4/I4Xrz0jhi7vP5zfj+rN+ZyFXPruAH7y6xEY5G+MnLAA0QeeYUIanduDDVqoGqqhUfvb2crL2FvHspGF0iT12VtLJo3uwc38xs2oZpfzBqh18u/MAd17YhyCP86sPDfIweXQPvrznfO4Z25evNuXzxOz1LX4txpi2ZwGgicYPSmLjroNsyC1s8c/6yycbmLchn4cvG8CIHh2O2z6mXyd6dIzg5a8yj2vcLauo5MlPN9Kvc9SRBmxvESGB3H5eLyaNTGFaejYZea1brWWMaX0WAJro4oFJBAgtPjXEN5l7eHbeZq4d0Z3rz0ipcZ+AAOEHZ6WyMns/S7cdW5//zpIstu0p4t6x/QgIkFo/56djehEW5OHPszc0a/6NMScenwKAiIwVkQ0ikiEi99Ww/RwRWSYi5SJylVf6+SKywutRLCKXu9teFZEtXtuGNN9ltZ6OkSGc1asjH6za0WJdKovLKrj/3dV07xDGb8b1r3Pf7w3rRkxYEC/P33Ik7XBpBX//fBPDU+M4r2/d6yrHR4Yw5ZyefLw21xqFjWnn6g0AIuIBngEuBvoD14pI9bvQduBm4C3vRFWdq6pDVHUIMAYoAj7x2uXuqu2quqLxl9G2xg/qwrY9RazO2d8i539mbgaZuw/xhysGEh5c9yJu4cGBXDcymdlrc8na6wxSe3XBVvIKS7hnbD/cFdvqNHl0DzpGhvDYrPWtOk5g/+EyG5dgTCvypQQwAshQ1UxVLQXeBiZ476CqW1V1FVDXwrlXAbNUte2GzraQiwZ0JsgjvDx/S7PPybMht5Dn5m3myqFdObt33d/eq9w0KpUAEaZ+vZX9RWU8Ny+DMf06MTz1+HaDmkSEBPKz7/Ri8Za9zNuQ35Ts+2Tn/sPcOW0Fg3/7Cf9dltPin2eMcfgSALoCWV7vs920hpoI/Lta2qMiskpE/ioiITUdJCJTRCRdRNLz81v+ZtQYMeFB3HbuKfxvxQ7u+s/KWrthNlRFpXLvf1cRHRbEr+up+vHWOSaUcYOSmJaexZ8/2UBhSTl3X9S3QZ89cUQyqfHh/Onj9VS00ERzh0rKefLTjZz/53l8uHInceFB/OsbW23NmNbSKo3AIpIEDMRZWL7K/UA/YDjQAbi3pmNV9UVVTVPVtIQE374Bt4U7L+zDPWP78t7yHH70xlIOl1Y0+ZxvLNzKiqwCHhzXnw4RwQ06dvLonhwsKeeNRdu4bHAXTk2KbtDxQZ4AfnlRX9bnFvL+8ub9Vl5RqUxLz+L8P8/j759v4junJvL5Xedy+3m9WL69gIy8lu9RZYzxLQDkAN293ndz0xriauA9VT0yT4Gq7lRHCTAVp6rppCUi3H5eL/5wxUDmbsjjhpe/YX9R3dMy1GVHwWGemL2Bc/okMGHI8d026zOwWwwjenQgMEC488I+jcrDJaclMbBrDE9+upHisqYHNHCua/w/5nPP9FV0iQ3jvz8exTPXnU73DuFcPrQrngBh+lKrBvIHFZU2jXlb8yUALAF6i0gPEQnGqcqZ0cDPuZZq1T9uqQBxWiUvB9Y08JwnpOtGJvPMdaezKns/17y4sFGLxqgqv3l/DZUKj15+mk8NtzV54qpBvHrLCFLiIxp1fECAcN/F/cgpOMybi45WzagqGXkHefHLzUx8cSG//3Cdz+d85IN1bNl9iL9fO5T3bj+TYSlH2yUSokI4v28C7y7LpryZqtGaym5SLWfCM/P57Qdr2zobfq3uLiWAqpaLyB041Tce4BVVXSsijwDpqjpDRIYD7wFxwHgR+a2qDgAQkVScEsQX1U79LxFJAARYAdzWTNfU5i4ZmER0aBBT3kjne88v4MUb0ujdKZJAj281bh+u2snn6/P49aWn0r1DeKPzkRIf0eibf5WzenXk7N4deXpuBj06RjA/Yzdz1uexbY/Tlp8YHcKizL2c2zeh3kbqhZv38PHaXO66sA+XDa65VHPVsO589m0eX2Xs5vy+nZqU96bYc7CE1xZu4/WFWxnSPZaXbkzz+fdn6rfnYAlrcg6wMfcgPxnTi05RoW2dJb8kJ1O3u7S0NE1PT2/rbPhsRVYBt0xdzL6iMkQgPiKETlEhdIoOITEqlNiIICorlbIKpbyykgr39Zz1eXSLC+O928/CU8egrdayJmc/4/4xH4DgwADOOiWeMacmMqZfJ+Ijgrn4b1+hqnz883OOzE1UXUWlMu4f8zlwuIzP7zq31v1Kyys544+fM6pnPM9MOr3Frqk22/cU8dL8TKalZ1FcVklaShzp2/Zx06gUfjvhtFbPT3v1+be7mPya83/5jvN78csGdlIwDSMiS1U1rXp6vSUA03hDusfywU9HM29DPnmFJeQdKCavsIRdB4pZu+MA+4vK8AQIgR4hMEAI9AQQFCB0jg7liasGnxA3f4DTusbwwg3DCBDhrF7xx41F+N2E07j+5W94dt7mWtsbpqVn8e3OAzx93dBab/7gBJgJQ7rwr0XbKSgqJTa8YY3fdamoVL7clM/h0gqCPAEEeYRgTwBBgQGUllfy9pIsPlq1A0+AcMXQrkw5pye9OkXx6Efr+OdXW+iVGMUNtYzCNg2zfHsBngDhrF4defObbdx+/in1jnExzc9+4i2sW1x4rVM3nEwuGtC51m2je3dkwpAuPD9vMxOGdOGUhMhjth8oLuPPszcwPDWOSwcm1ftZVw3rxtSvtzJj5Q5uHJXa1Kwf8bfPNvL3ORm1bo8KCeTWc3ryg7N6kBh9tErivotPZXP+IR6esZYe8RGM7t2x2fLkr1ZkFdA3MYr/G9OLq55fyPSl2c36uza+sQBgmsWvL+3PnPV5/Ob9NfzrhyOPabh+ek4Ge4tKeXXcCJ8atAd0ieHUpOhmvSks3rKXp+dmcOXQrvzo3FMoq6iktKKSsvLKI1Vwp6fEER0adNyxngDhbxOH8L3nFnD7v5by/k/Oome1IHey2bn/MK8t2Mb0pVkM6hbLY98b2Gr18JWVysqsAsYP6cKwlDiGdI/l5flbmDQy5YQp9foLCwCmWSREhXDv2H78+v01vL8ihyuGdgNgy+5DTP16C1ed3o2B3WJ8Pt/3h3XjkQ/XsSG3kL6do5qUt/2Hy/jFOyvo3iGcRy4/jciQhv/ZR4UG8fJNw5nwzNdMfi2d928/i5jwo8GivKKSrzfv4b1l2SzbXkBkSCCx4UHEhgcRExZMXHgQCVEhXHm6M1dTfQ6WlPPEx+tJiY/gB6N7NDi/tVmTs5+X52/hg5U7qFTlnD4JLNi8m4uf+oonvj+IMf0Sm+2zapO5+yCFJeUM7R6LiHDr2T35yVvL+HTdLsaeVntJ0zQ/CwCm2Vw3Ipn/Lsvm9x9+y/l9OxEbHsyjHwxEn0EAAB9iSURBVH1LsCeAu8c2rJFvwpAu/GHmt0xfmsUDl/o+Crq6qi61uQeKmX7bqEbd/Kt07xDOCzcM47p/LuL2t5by6i0j2JBbyHvLc5ixcgf5hSVEhwYyundHSssrKSgqY+OugxQUlVFQVEp5pfLCF5k88f1BdfaYWrtjPz99azmZuw8R5BG+OyCRbnGN7w0G8MXGfJ6ft5mFmXuICPZw46hUbjkrle4dwsnIK+Sn/17BD15N58ZRKfzqklPrbKdpqmXbCwAYmhwLwEUDEukWF8ZLX2VaAGhlFgBMswkIEB69fCDjn57Pnz7ewKUDk/js213cM7Zvg6sX4iND+M6pnXhv+Q7uGdvvyAI2VVSV95bnUFhczqSRybV20Xx/hXNz/uV3+zA0Oa7R11ZleGoH/nDFQO6evopRf/yc3QdLCfII5/ftxJWnd+W8vp1qvHmqKquy93PXf1Zyw8uLueGMFO6/pN8xDZ+qypvfbOd3H64jLjyIv00cwt3TV/G3zzbxxPcHNzrP32Tu4aZXFpMUE8r9F/dj4ojkY0ohvTpF8f5PzuTxjzfw8vwtLMrcw9+vHUq/zg0bPe6rFVkFRIUG0rOjU40W6Alg8uge/PaDdSzbvo/Tm+H3ZHxj3UBNs6vqNdMlJhSPR/j0F7V3+6zLp+t2cevr6bx0YxoX9D9aNZGZf5BfvbeaRZl7ARjQJZo/fW8Qp3U9topp+54iLvn7V/RPiubfU85o1vrlf3y+ifkZuxk3uAvjBiYR5+NUHcVlFTwxewOvfL2FlA7h/OXqIQxLiWP/4TLuf3cVM1fncl7fBP7y/cHER4bwuw/XMfXrLXzyi3Pp1alx7Q6TXlrEhtyDfHXP+YQF1/17+GJjPndNW8mB4jIeGt+fSSObvwPDJX/7ivjIYN6YPPJI2qGSckb98XNG9+7Is5OG1XhceUUlW3YfIiTQQ3iIh/BgD2FBnkYPlPQn1g3UtJqfX9CHD1ftZMf+Yp6bdHqjqxPO65tAx8hgpi/N5oL+iZSWV/LCF5v5x9wMQgMDeOzKgcSEBfHQjLVc9vR8fnh2T35xQR/Cgj2UV1Ty83eWIwJPXtP8XWp/+p3e/PQ7vRt8XGiQh9+M688Fpybyy/+s5PvPL+CGM1KYsyGPnQXF3H9xP249u+eRRXtuP+8U3l68nb9+urFR4yKWbtvH1xl7+NUl/eq9+QOc2yeBj39+NndNW8kD762hsLic2849pcGfW5ui0nLW5x7gJ+f3OiY9IiSQ60am8OKXm8naW3TcAMiVWQXc/+5q1u08cEy6CIQFeYgNC+J7w7pxy1k9Gjxvlj+zAGCaXURIIM9OOp0Fm/c0qU43yBPA5UO68trCrXy6bhePf7yeTXkHGTcoiQfH9z9SrXRmr448Nms9L36Zyaw1O/nDFQNJ37qPZdsL+Pu1Q5tcf94SRp0Sz8c/P5vffbiO1xZuo2tsGNNuG3Vc9Ud8ZAiTR/fg73My+HHO/uNKOfX5x5xNxIUHNeibfMfIEF66KY07p63ksVnrKS2v5P8aEexqsjp7P5XqjJGp7uYzU3npq0xenr+Fhy8bAEBhcRl/+WQjry3cSqeoEH53+WmEBXkoKi2nqLSCohLnOXP3If4xJ8PtTZTMrWf3pFP0iTm6+C+fbCAyJJAfNWNgbSyrAjIntPW5Bxj71FcAdI0N43eXD6i1p8o3mXu4/73VZOYfQgSuGNqVJ68+8ReaW5Ozn+T48Bq7oIIzjuLsP81laHIsr97i+5yJq7ILuOzpr7n7or7HfeP2RUWlcvd/VvLu8hzuOL8Xd323T5OrW174YjN/nLWepb++gPjI42eAv/OdFXy8NpeF932HhZl7eHjGWnYVFnPjGSncdVHfWn9GABt3FfLs3AxmrNxBoCeAq9O68aNzTmnSdCrNbUHGbq576RuiQgJZ8usLWrSx3ZtVAZmTUr/O0UwamUx4sIefX9CHiDp68YzsGc/M/zubZ+dmsDyrgN+63yJPdPV9q48ODeLH553CY7PWs3jLXkb08G1hn6fnZBAdGsiNoxpXj+8JEJ74/mCCAwN4em4GpRWV3H+xb6vK1WZFVgHJHcJrvPkD/PDsnry7PIfxT89n+94i+nWO4rnrT/epAb9PYhRPTRzKLy7sw/NfbOadJVm8vTiLhy4bcEKM4C4uq+CB99cQEeyhsKScLzbm1znAsjX4x+xW5aVQsL2tc2Ea6dErBvLApf3rvPlXCQ3ycOd3+/LG5JFE1fFt8WRz06hUEqJCeGK2b8t0frvzAJ+s28UtZ/Vo0s/BEyD84YqB3HBGCi9+mclvP1jXpGU7l28vqLH6p0r/LtGc2yeBvEKnPeSDn45ucO+tlPgI/njlIL6853zO6ZPAg/9bw0erdjY6z83luXmb2bL7EE9POp248CA+PAHy5B8B4M0rYdqNcBJVdxnjLSzYw/+N6cWSrfv4YmP9K+M9PTeDyJBAfnBW0weRBQQIj0wYwOTRPXh1wVYe/F/jpnDO3V9M7oHiOgMAwLOTTmfR/d/hR+eeclz334ZIignj2UmnMyw5jl+8s4KFm/c0+ly1qaxUZq/N5WBJeZ37bc4/yHPzNnPZ4C6c37cTFw9M4vNvdzXLwlFN4R8BYNA1sGM5bPq0rXNiTKNdMzyZbnFhPDF7Q51rFGTkFTJz9U5uHJVyzGjlphARfn3pqfxwdA/eWLSNuevzGnyOFVn7ABiSXHcAiAgJbLZJAEODPLx0UxrJ8eFMeT2db6v1ImqqGSt38KM3ljLxxYXkF5bUuE/VYMSQoAB+Pe5UAMYNSqKotII5jfg5Nif/CACDJ0JsCsz7o5UCzEkrODCAX1zQh7U7DvDx2txa93tm7mZCAz1MbsYpJMAJAveM7UfPhAh++8FaSsob9u11+fYCgj0BDOjSMgPMahMbHsxrPxhBREggN09dTPa+omY5r6ry/BebSYoJZXPeIa56fgHb9hw6br/3luewYPMe7h3b70jPtZE94kmICuGDlTuaJS+N5R8BwBME5/wSdiyzUoA5qV0+tCu9OkXy4P/W8uy8DHZVW3Fu6+5D/G9FDpNGJtfa0NoUwYEBPDx+AFv3FPHSV1sadOzyrAJO7RJNSGDr9Hzx1jU2jFd/MJyi0gpuemUx+w6VNvmcX27azfrcQu68sA9v3TqSA4fL+N5zC1iTs//IPgVFpTz60bcMTY7luhHJR9I9AcIlp3Vm7oa8equPVJWtu48PLM3BpwAgImNFZIOIZIjIfTVsP0dElolIuYhcVW1bhYiscB8zvNJ7iMg37jnfcZebbDmDr4XYZPjiMSsFmJOWJ0D469VD6Nkxgsc/3sCZj81h8qtL+HhNLmUVlTw7L4NATwBTzunZYnk4p08CFw1I5Ok5GewoOOzTMeUVlazO3s/Qeur/W1K/ztH888Y0svYeZvJrS5pc//7CF5tJjA5hwpCuDE2OY/qPzyQk0MM1Lyzk64zdADw2az0Fh8v4wxUDjwzuqzJ+cBdKyiv5bN2uOj/nveU5XPDkF6zIKmhSfmtSbwAQEQ/wDHAx0B+4VkSqz861HbgZeKuGUxxW1SHu4zKv9D8Bf1XVXsA+YHIj8u87TxCcfRfkLIWMz1r0o4xpSQO7xTDttlHMuetcppzTk9U5+7ntzaWM+uPnvLssh2uHd2/xQVC/vrQ/lao8OvNbn/bfuOsgh8sqjkwA11bO6BnPUxOHsDyrgB+9ubTRQWBVdgELNu9h8ugeBAc6t9FTEiL574/PpFtcODdPXczjH6/n7SVZTB7dg1OTjq/2Oj05jqSYUD5cVXs1UGFxGX+YuZ7TusYwqIGDAH3hSwlgBJChqpmqWgq8DUzw3kFVt6rqKsCnlbzdheDHANPdpNdwFoZvWYOvg5hkmGelAHPy65kQyb1j+7HgvjG8fFMaw1Li6BIbxm3ntfwI0+4dwrn9vF58tGonC9xvu3VZXtUA3IYlgCqXDEzisSsH8tWmfG6aupjC4rIGn+OFLzOJCgnkWq9qHYDOMaFM+9EohnaP49l5m+kaG8bPL6h5FHVAgHDpwCS+2JjP/qKa8/C3zzax51AJj0wYcFwJojn4EgC6Alle77PdNF+Fiki6iCwSkaqbfDxQoKpVlV+1nlNEprjHp+fn19/9rU6BwXD2nZCTDhmfN+1cxpwgAj0BfOfURF64IY0v7zmfpJiwVvncH53bk+4dwnj4g7WUVdT93W/F9gI6RASTfIKMyr1meDJPXTOEZdv2cf1L3zSoTWDbnkPMWr2TSWek1DjGIiY8iNcnj+DH553C368dWudSl+MHd6GsQpm97vhG/Y27Cpm6YCsTh3dnULeWCZyt0Qic4g5Bvg54SkQa9PVEVV9U1TRVTUtIqH0OdZ8NmQQx3a0twJgmCg3y8JtL+7Nx10FeX7itzn1XZBUwuFvMCTVz54QhXXn++mF8m1vIxBcXkVetQb02//wqk8CAAG45K7XWfUKDPNw7th/DUuoexDaoWwzJHcKPGxSmqjw8Yy2RIYHcfVE/n/LVGL4EgBygu9f7bm6aT1Q1x33OBOYBQ4E9QKyIVIXGBp2zSapKAdlLYLOVAoxpigv7J3JunwSe+nQjeYU130APFJeRkX+wWdZjaG4X9E9k6s3DydpXxNUvLKy3i+jugyX8Jz2bK4Z2PWbd6MYSES4dlMTXGbvZ61UKmbk6lwWb9/DL7/Zp0dlNfQkAS4Debq+dYGAiMKOeYwAQkTgRCXFfdwTOAtapM5Z8LlDVY+gm4H8NzXyjDbkeortZW4AxTSQiPDS+P8XlFfxp1oYa91mVtR+tZQbQE8FZvTryxuSR7DlUytXPLyQz/2Ct+76+YCsl5ZXc2oy9rMYNSqKiUpm1xikFFJWW8+hH6+ifFM11LbAeg7d6A4BbT38HMBv4FpimqmtF5BERuQxARIaLSDbwfeAFEakaK34qkC4iK3Fu+I+p6jp3273AnSKSgdMm8HJzXlidjikFzGm1jzWmPeqZEMkPz+7Jf5dlc+vr6SzesveY+YKqRgAPPkEDAMCwlDjennIGJeWVjP/HfP48ewMFRce2CxwqKee1hdu4sH9ioxfnqUn/pGh6JkTw4UonADw7dzM79hfzyIQBzb6ORXU+zQaqqjOBmdXSHvR6vQSnGqf6cQuAgbWcMxOnh1HbGHo9fPUkzH0UepzjdBM1xjTKz77Tm6AA4Y1F2/h03S4GdYth8ugeXDIwiRVZBfRMiDhmGcoT0YAuMbx3+1k8Pns9T8/N4LUFW7lldA8mj+5BTFgQ09Kz2H+4jNvObd4xFiLCuEFdeHrOJpZs3cuLX2ZyxdCupKX6Nutrkz7br9cDWPk2vPcj6H0RXP0aBLVO7wlj2qvDpRW8uzybl+dvITP/EEkxoRQWl3PRgM785erGr2vc2tbnHuBvn21i1ppcokIDmTy6B/9JzyYpJpTpPz6z2T9v065CLvzrl0SFBlJZqcz95XnNOpajtvUA/GMqiNoMngiXPgmbPoE3r4Li5p0oyhh/ExbsYdLIFD77xbm8cnMaqfERHCwp58xT4ts6aw3Sr3M0z10/jJn/dzajesbz1GebyCk43GKrePVOjKJvYhSFxeX8/II+rbaamX+XAKqsnu6UBBJPg+vfhYiT64/VmBNZXmExCZEhJ1QX0IZak7OfFVkFXDciuUUGZAFMX5rNByt38M8b046MLm4utZUALABU2TjbWTMgNgVufB+iu7TM5xhjTCuzKqD69LkIrv8vHNgBr1wEeza3dY6MMaZFWQDwljoabpoBJQdh6sWQu6atc2SMMS3GAkB1XU+HW2aBeGDqJbBtQVvnyBhjWoQFgJp06geTP4HITvDGFbB+Zv3HGGPMScYCQG1iu8MPZkPiAHhnEix7o61zZIwxzcoCQF0i4uHGGdDzPJhxB8z/q80dZIxpNywA1CckEq59B067Cj57GGY/AJU+rXtjjDEnNJ/mAvJ7gcFw5T8hPB4WPQMbP4ZhNztrC9igMWPMScpKAL4KCICL/wRXvQIRCfDpb+DJfjB9Mmydb1VDxpiTjpUAGkIETvue88j7FtKnOhPKrZkOHfvA6Dud+YVO4iHvxhj/YSWAxup0KlzyONy1HiY8C0Hh8P5t8OaVsK/u5fGMMeZE4FMAEJGxIrJBRDJE5L4atp8jIstEpFxErvJKHyIiC0VkrYisEpFrvLa9KiJbRGSF+xjSPJfUyoLDYegkuHUuXPJnyFoMz46Cb16wxmJjzAmt3gAgIh7gGeBioD9wrYj0r7bbduBm4K1q6UXAjao6ABiLsyi897JAd6vqEPexopHXcGIICIARt8LtiyBlFMy6B6aOhfyal8kzxpi25ksJYASQoaqZqloKvA1M8N5BVbeq6iqgslr6RlXd5L7eAeQBCc2S8xNVbHeYNB2ueAF2b4TnR8PMe5wpp/M3QGVFW+fQGGMA3xqBuwJZXu+zgZEN/SARGQEEA97TbD4qIg8CnwP3qWpJDcdNAaYAJCcnN/Rj24aI0xh8yhj4+H5YOhUWv+BsCwyDxP7QeSB06g8x3SAqCaK7Or2LAqxZxhjTOlqlF5CIJAFvADepalUp4X4gFycovIizSPwj1Y9V1Rfd7aSlpZ1cfS0jO8FVL0N5qVMayF3tPlbB2vdg6avH7h8QeDQYdEuDlLMg+QwIb/m1QY0x/seXAJADdPd6381N84mIRAMfAQ+o6qKqdFXd6b4sEZGpwC99PedJJzAYOp/mPLjWSVOFg7uc9QcO7IDCnUef926Bxf+EhU8D4sxHlHKm8+g8yFm0xmM9eI0xTePLXWQJ0FtEeuDc+CcC1/lychEJBt4DXlfV6dW2JanqTnHWibsc8K/J90UgqrPz6Hr68dvLimHHMtj6NWz7Gpa/CYtfdLZ5gqHDKdCxtzP+oGMfZwbThH4QGNK612GMOWn5tCSkiFwCPAV4gFdU9VEReQRIV9UZIjIc50YfBxQDuao6QESuB6YCa71Od7OqrhCROTgNwgKsAG5T1YN15aNFl4Q80VWUwc5VkP+tU520O8N53psJ6jYsBwQ6QSDxNKeNoephVUjG+DVbE7i9Ki+FfVsgb51XG8NqpyqpSmwKdBkCSUOOPltQMMZv1BYArCL5ZBcYDAl9nceAK46mH8yHXath50rYsQJ2roB1/zu6PSYZ4k+BDj2PfcSlQlBoq1+GMab1WQBoryITIHKM0xW1StFeJyDsXOGsd7w305nHqHi/b+cMiXa6qkZ2goiOENHJeR+VCNHdILoLxHSF0FibD8mYk4AFAH8S3gFOOd95eCva6/Q82psJBVuhovz4Y7USSg7AwTw4lA+7NzkN1If3Hr9vULgTDCITITAUgsLc51BnHERIJMR0d0obcanO68DgFrhgY0xdLAAYJzCEd4Buwxp+bEWZExQO5DiP/Tlu19ZsOLQbDu9z2iPKDkN5CZQfhpKDUFl29BwS4JQg4lKcLq+dB0HSYKdayxNU8+eqHi25hMXWvI8xpk4WAEzTeIKcap+Yrr4fU1kJB3Nh31an5LFvq/s6E5a9DmVF7rlD3FHTg5weTgd3eT3yoLzY2S8k2hlRHdPNKU3EdIPY5KNpkZ1t3IQxNbD/Fab1BQQ4VUTRXZzBbd4qK2DPZqetInel0/X12xnOtsjOTvtD9zOcdofIRKcksD/bfWRB9hKn1OFNPO7ndYXoJKcayhPkPALcZ0+wMyajqjE8prsFDdPu2V+4ObEEeCChj/MY9P3GnaPkoBMQDmR7BQf3sXMVVJQ6VVcVpVBZfvS1ek3UFxDolCI69ISwOKea6shDnGdPiFP9FBrr9RznLB0am+xMFW7MCcwCgGl/QiKdkdGd+vl+TFW1VFVj+N5MZ3zF3kwnTSudAKHqvq502jWK9wO1jKWJTIS4Hkcbu+NS3RJGD6f3lPWUMm3MAoAxcGy1VOpZvh9X6faOOrwPigvgcIHT+F2wFfZuddo2ts6HVe9wTKAIjnSCQ4dU5zky0Sk9HPOIdfYLDHFKJBYwTDOzAGBMUwQEODfq+noilZdAwfajJYx9W5zX+Rtg42ynCqouVVVOge7DE+J0nfUEH23D8IQ47RbicarSxOMcFxDgBJDAMAiOcKqmgiLc1xHODLQdejgjxm0QoF+xAGBMawgMcSfv6338tspKKC10ShHej6K9To+o8lKnx1NFiduVtsRtx3Af5aVH2zVKi5yqqsqKo1VVlRVOW0d5MZQedPapOG7pDUCcElBc6tHSSWyK84hLcUopVgppVywAGNPWAgIgNMZ5xKW2zmdWlEPZISg95IzdqCqRVD1nfOp0t/UWGOo0bkcmHk1TBdR5DvA4vbSiu0BUl6NValFJTknD41VisUByQrAAYIw/8gSCxw060V2g+/Dj9yktcqqtCrY5z/u2Oq8P7XZ3EPdGLk4QqyyHnGWw/qOjYzRq/Xw3GER2cqY2j+/lzE0V776O7uoEFNOiLAAYY2oWHN7w3lTglAYO7zt2oaPy4hqqrkqcbXs3O2teVA0ArBIUASFR7iPSeQ6KqL304N1FFznabde7q693F2BPkNPIHhLpPkc7ryXAacwv3n+0Yb94v1NiCgxzpjYJCnfbUsKcPEUneQ1EdAcjhkQ26sfemiwAGGOal8jR6UU6n+bbMapQmAt7MpxHYa7TXlFywBnXUVLoPKoP8jtyvPtPVbuHVh7tshsQWK2xPAiCop1AULTbKdmUup9R6i5JEhzlju2IccZ3dOjh3PTLi51AVXbYmROr7LBzXGHuseNIwDku/hTo2Ncd29LPWbwpLvWEKd34FABEZCzwN5wFYV5S1ceqbT8HZ8GYQcBE79W/ROQm4Nfu29+r6mtu+jDgVSAMmAn8TE+mxQmMMc1HxPkWHZ0EPc5uu3xUusGjoaPAKyucIFA1In1/tlNtticDNs+BlW8d3dcT4rSjBIVWmywxzAkax4wb6dGije/1XqWIeIBngAuBbGCJiMxQ1XVeu20Hbqbaur4i0gF4CEjDidFL3WP3Ac8BtwLf4ASAscCspl6QMcY0WkAAENCI4zxec2KNPH774QJnBt389bB7g9OOUnbYLVG4z4f3wa61sHqaE4SqBIY5weCaN2ruRdYEvoS5EUCGqmYCiMjbwATgSABQ1a3utspqx14EfKqqe93tnwJjRWQeEF21SLyIvI6zLrAFAGNM+xMW6zS019TYXl15qVOKqOqVVTVZYljzr+LnSwDoCmR5vc+mxhDn87Fd3Ud2DenHEZEpwBSA5ORkHz/WGGNOUoHBR3tEtbBGlHVal6q+qKppqpqWkJDQ1tkxxph2w5cAkAN093rfzU3zRW3H5rivG3NOY4wxzcCXALAE6C0iPUQkGJgIzPDx/LOB74pInIjEAd8FZqvqTuCAiJwhIgLcCPyvrhMZY4xpXvUGAFUtB+7AuZl/C0xT1bUi8oiIXAYgIsNFJBv4PvCCiKx1j90L/A4niCwBHqlqEAZuB14CMoDNWAOwMca0KjmZut6npaVpenp6W2fDGGNOKiKyVFXTqqef8I3AxhhjWoYFAGOM8VMWAIwxxk+dVG0AIpIPbGvk4R2B3fXu1f7YdfsXf71u8N9r9+W6U1T1uIFUJ1UAaAoRSa+pEaS9s+v2L/563eC/196U67YqIGOM8VMWAIwxxk/5UwB4sa0z0Ebsuv2Lv143+O+1N/q6/aYNwBhjzLH8qQRgjDHGiwUAY4zxU34RAERkrIhsEJEMEbmvrfPTUkTkFRHJE5E1XmkdRORTEdnkPse1ZR5bgoh0F5G5IrJORNaKyM/c9HZ97SISKiKLRWSle92/ddN7iMg37t/7O+4svu2OiHhEZLmIfOi+b/fXLSJbRWS1iKwQkXQ3rdF/5+0+AHitaXwx0B+4VkT6t22uWsyrOGsre7sP+FxVewOfu+/bm3LgLlXtD5wB/MT9Hbf3ay8BxqjqYGAIznKrZwB/Av6qqr2AfcDkNsxjS/oZzgzFVfzlus9X1SFeff8b/Xfe7gMAXmsaq2opULWmcbujql8Ce6slTwBec1+/hrP2cruiqjtVdZn7uhDnptCVdn7t6jjovg1yHwqMAaa76e3uugFEpBtwKc6U8rjrirT7665Fo//O/SEA1LYusb9IdBfgAcgFEtsyMy1NRFKBocA3+MG1u9UgK4A84FOctTUK3HU8oP3+vT8F3ANUuu/j8Y/rVuATEVnqrpcOTfg792VReNNOqKqKSLvt9ysikcB/gZ+r6gHnS6GjvV67qlYAQ0QkFngP6NfGWWpxIjIOyFPVpSJyXlvnp5WNVtUcEekEfCoi6703NvTv3B9KAE1Z07g92CUiSQDuc14b56dFiEgQzs3/X6r6rpvsF9cOoKoFwFxgFBArIlVf7trj3/tZwGUishWnSncM8Dfa/3Wjqjnucx5OwB9BE/7O/SEANGVN4/ZgBnCT+/om2uHay27978vAt6r6pNemdn3tIpLgfvNHRMKAC3HaP+YCV7m7tbvrVtX7VbWbqqbi/H+eo6qTaOfXLSIRIhJV9RpnjfU1NOHv3C9GAovIJTh1hh7gFVV9tI2z1CJE5N/AeTjTw+4CHgLeB6YByThTaV/ttS5zuyAio4GvgNUcrRP+FU47QLu9dhEZhNPo58H5MjdNVR8RkZ4434w7AMuB61W1pO1y2nLcKqBfquq49n7d7vW9574NBN5S1UdFJJ5G/p37RQAwxhhzPH+oAjLGGFMDCwDGGOOnLAAYY4yfsgBgjDF+ygKAMcb4KQsAxhjjpywAGGOMn/p/xgTmgF/9Gs0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Retrieve a list of accuracy results on training and validation data\n",
        "# sets for each training epoch\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "# Retrieve a list of list results on training and validation data\n",
        "# sets for each training epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and validation loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-fUIeizakjE"
      },
      "source": [
        "Congratulations! Using feature extraction and fine-tuning, you've built an image classification model that can identify cats vs. dogs in images with over 90% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ANwJCnx7w-"
      },
      "source": [
        "## Clean Up\n",
        "\n",
        "Run the following cell to terminate the kernel and free memory resources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-hUmyohAyBzh"
      },
      "outputs": [],
      "source": [
        "#import os, signal\n",
        "#os.kill(os.getpid(), signal.SIGKILL)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "03_cnn_G.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}