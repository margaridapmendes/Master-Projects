{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image Classification with SciKit-Learn.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP8yQTMccXDkILrwvP2jPmI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Image Classification SciKit Learn"],"metadata":{"id":"7bflqLhIGMkn"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zP6awiBcF94E","executionInfo":{"status":"ok","timestamp":1643817332534,"user_tz":-60,"elapsed":2002,"user":{"displayName":"Margarida Pacheco Mendes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvX-LUD0DhPFAcm8Sn_vBpTAcxsYl7wZfm5hFu=s64","userId":"02665512111204092799"}},"outputId":"5521fe32-5ab7-48cd-9577-8f2c0f7d5aff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["#extra\n","import numpy\n","from keras import backend as K\n","from keras.datasets import mnist\n","from keras.utils import np_utils\n","from keras.layers import Dense, Dropout,Flatten\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.models import Sequential\n","import pandas as pd\n","K.set_image_data_format('channels_last')\n","numpy.random.seed(0)"],"metadata":{"id":"PzUCbPp_4D4F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"pFqMyJqp4_eF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = '/content/gdrive/My Drive/Computer Vision/Assignment/clothing-dataset-tiny/clothing-dataset-tiny/train'\n","test ='/content/gdrive/My Drive/Computer Vision/Assignment/clothing-dataset-tiny/clothing-dataset-tiny/test'\n","\n","y = X[\"label\"]\n","X.drop([\"label\"], inplace = True, axis = 1)"],"metadata":{"id":"JphLhFf44S-B","colab":{"base_uri":"https://localhost:8080/","height":215},"executionInfo":{"status":"error","timestamp":1644484180386,"user_tz":-60,"elapsed":249,"user":{"displayName":"Margarida Pacheco Mendes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvX-LUD0DhPFAcm8Sn_vBpTAcxsYl7wZfm5hFu=s64","userId":"02665512111204092799"}},"outputId":"9be22a49-093f-4887-c967-7988d601e299"},"execution_count":1,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3f63da8b6ed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/Computer Vision/Assignment/clothing-dataset-tiny/clothing-dataset-tiny/test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: string indices must be integers"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2 , random_state=42)"],"metadata":{"id":"_Y5atLwS4UtL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"qSJiLt0A4-ps"}},{"cell_type":"code","source":["X_train = X_train.reshape(X_train.shape[0], 28, 28 , 1).astype('float32')\n","X_test = X_test.reshape(X_test.shape[0], 28, 28 , 1).astype('float32')"],"metadata":{"id":"GrC4QOE_4Wsv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.layers import Dropout\n","\n","model = Sequential()\n","\n","model.add(Conv2D(100, kernel_size=3, padding=\"valid\", input_shape=(28, 28, 1), activation = 'relu'))"],"metadata":{"id":"bUufxghm4aR_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.add(Conv2D(100, kernel_size=3, padding=\"valid\", activation = 'relu'))\n","model.add(Conv2D(100, kernel_size=3, padding=\"valid\", activation = 'relu'))\n","\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))"],"metadata":{"id":"3mH-q32f4cMx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.layers.core import Activation\n","\n","model.add(Flatten())\n","model.add(Dense(units= 500, activation='relu'  ))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(10))\n","model.add(Activation(\"softmax\"))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"metadata":{"id":"gwNaRhwh4ea-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = np_utils.to_categorical(y_train).astype('int32')\n","y_test = np_utils.to_categorical(y_test)"],"metadata":{"id":"-lyPhzru4hd2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","\n","callbacks = [\n","    keras.callbacks.EarlyStopping(\n","        # Stop training when `val_loss` is no longer improving\n","        monitor='val_loss',\n","        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n","        min_delta=1e-3,\n","        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n","        patience=25,\n","        verbose=1)"],"metadata":{"id":"EF711Ag64lET"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","X_train = X_train.reshape(-1,28,28,1)\n","X_test = X_test.reshape(-1,28,28,1)\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","    featurewise_center=True,\n","    featurewise_std_normalization=True,\n","    rotation_range=10,\n","    fill_mode='nearest',\n","    validation_split = 0.2\n","    )\n","\n","datagen.fit(X_train)\n","\n","train_generator = datagen.flow(X_train, y_train, batch_size=60, subset='training')\n","\n","validation_generator = datagen.flow(X_train, y_train, batch_size=60, subset='validation')\n","\n","\n","# fits the model on batches with real-time data augmentation:\n","history = model.fit_generator(generator=train_generator,\n","                    validation_data=validation_generator,\n","                    use_multiprocessing=True,\n","                    steps_per_epoch = len(train_generator) / 60,\n","                    validation_steps = len(validation_generator) / 60,\n","                    epochs = 300,\n","                    workers=-1)"],"metadata":{"id":"oc_Kftt24nHk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prep_data (folder):\n","    # iterate through folders, assembling feature, label, and classname data objects\n","    import os\n","    import numpy as np\n","    import matplotlib.pyplot as plt\n","\n","    class_id = 0\n","    features = []\n","    labels = np.array([])\n","    classnames = []\n","    for root, dirs, filenames in os.walk(folder):\n","        for d in sorted(dirs):\n","            print(\"Reading data from\", d)\n","            # use the folder name as the class name for this label\n","            classnames.append(d)\n","            files = os.listdir(os.path.join(root,d))\n","            for f in files:\n","                # Load the image file\n","                imgFile = os.path.join(root,d, f)\n","                img = plt.imread(imgFile)\n","                # The image array is a multidimensional numpy array\n","                # - flatten it to a single array of pixel values for scikit-learn\n","                # - and add it to the list of features\n","                features.append(img.ravel())\n","                \n","                # Add it to the numpy array of labels\n","                labels = np.append(labels, class_id )\n","            class_id  += 1\n","            \n","    # Convert the list of features into a numpy array\n","    features = np.array(features), np.dtype (object)\n","    \n","    return features, labels, classnames\n","\n","\n","# The images are in a folder named 'train'\n","training_folder_name = '/content/gdrive/My Drive/Computer Vision/Assignment/clothing-dataset-tiny/clothing-dataset-tiny/train'\n","\n","# Prepare the image data\n","features, labels, classnames = prep_data(training_folder_name)\n","print(len(features), 'features')\n","print(len(labels), 'labels')\n","print(len(classnames), 'classes:', classnames)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":456},"id":"LZ9vQ_R7G5w5","executionInfo":{"status":"error","timestamp":1643819317783,"user_tz":-60,"elapsed":4513,"user":{"displayName":"Margarida Pacheco Mendes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvX-LUD0DhPFAcm8Sn_vBpTAcxsYl7wZfm5hFu=s64","userId":"02665512111204092799"}},"outputId":"8aeb281d-c0ea-49b9-db7c-dcc2d98b7180"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading data from dress\n","Reading data from hat\n","Reading data from pants\n","Reading data from shoes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-abdb157b56d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Prepare the image data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_folder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-41-abdb157b56d3>\u001b[0m in \u001b[0;36mprep_data\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Convert the list of features into a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object() takes no arguments"]}]},{"cell_type":"code","source":["print('Feature Shape:',features.shape)\n","print('Labels Shape:',labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AerKh_MMHFtH","executionInfo":{"status":"ok","timestamp":1643818856002,"user_tz":-60,"elapsed":261,"user":{"displayName":"Margarida Pacheco Mendes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvX-LUD0DhPFAcm8Sn_vBpTAcxsYl7wZfm5hFu=s64","userId":"02665512111204092799"}},"outputId":"e124a6b1-7d63-4114-b8ef-e28f78383c49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Feature Shape: (823,)\n","Labels Shape: (823,)\n"]}]},{"cell_type":"markdown","source":["Split the data\n"],"metadata":{"id":"ofD18_7OKhvL"}},{"cell_type":"code","source":["# split into training and testing sets\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.30)\n","\n","print('Training records:',Y_train.size)\n","print('Test records:',Y_test.size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eEoo4oEhKdk0","executionInfo":{"status":"ok","timestamp":1643818858493,"user_tz":-60,"elapsed":277,"user":{"displayName":"Margarida Pacheco Mendes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvX-LUD0DhPFAcm8Sn_vBpTAcxsYl7wZfm5hFu=s64","userId":"02665512111204092799"}},"outputId":"a3e4e0d0-f462-4907-aa9a-04dacb258cb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training records: 576\n","Test records: 247\n"]}]},{"cell_type":"markdown","source":["Train the Classification Model"],"metadata":{"id":"YR_ybSrpM1dK"}},{"cell_type":"code","source":["# Train the model\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Convert the training features to floats so they can be scaled\n","X_train_float = X_train.astype('float64')\n","\n","# Our pipeline performs two tasks:\n","#   1. Normalize the image arrays\n","#   2. Train a classification model\n","img_pipeline = Pipeline([('norm', MinMaxScaler()),\n","                         ('classify', DecisionTreeClassifier()),\n","                        ])\n","\n","# Use the pipeline to fit a model to the training data\n","print(\"Training model...\")\n","clf = img_pipeline.fit(X_train_float, Y_train)\n","\n","print('classifier trained!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"Oj2IsC09M5e3","executionInfo":{"status":"error","timestamp":1643818860187,"user_tz":-60,"elapsed":260,"user":{"displayName":"Margarida Pacheco Mendes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvX-LUD0DhPFAcm8Sn_vBpTAcxsYl7wZfm5hFu=s64","userId":"02665512111204092799"}},"outputId":"0c2cb124-84f8-42e8-dcba-b2a2a9659cf8"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-f6affa1daed0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Convert the training features to floats so they can be scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Our pipeline performs two tasks:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."]}]},{"cell_type":"code","source":[""],"metadata":{"id":"aO4oSGTeM99F"},"execution_count":null,"outputs":[]}]}